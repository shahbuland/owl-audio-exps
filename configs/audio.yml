model:
  model_id: audio_rft
  sample_size: 120  # n_latent_samples from VAE
  channels: 64     # latent_channels from VAE

  n_layers: 16
  n_heads: 16
  d_model: 1024

  tokens_per_frame: 1  # each latent is one token for audio
  n_frames: 10000       # reinterpreted as n_latent_samples

  cfg_prob: 0.0        # no CFG for unconditional generation
  causal: true         # causal attention for audio generation
  uncond: true         # unconditional generation
  backbone: dit
  has_audio: true      # this is audio data
  rope_impl: audio1d   # use 1D RoPE implementation

  local_window: 16
  global_window: null  # full window

  gradient_checkpointing: false

train:
  trainer_id: audio_rft
  data_id: local_waveform
  data_kwargs:
    window_length: 88200
    root_dir: /mnt/data/datasets/cod_yt_latents

  target_batch_size: 256
  batch_size: 32

  epochs: 10000

  opt: AdamW
  opt_kwargs:
    lr: 1.0e-4
    betas: [0.9, 0.999]
    weight_decay: 0.01
    eps: 1.0e-8

  scheduler: null

  checkpoint_dir: checkpoints/audio_dit_v4
  output_path: /mnt/data/owl-wms/checkpoints/audio_dit_v4
  resume_ckpt: null

  sample_interval: 5000
  save_interval: 5000

  sampler_id: audio_caching
  sampler_kwargs:
    n_steps: 2
    num_tokens: 120  # Generate 2s of new audio
    noise_prev: 0.2

  n_samples: 4
  eval_sample_dir: null

  vae_id: null
  vae_batch_size: 4

  vae_scale: 0.0357
  vae_cfg_path: /mnt/data/shahbuland/owl-vaes/configs/cod_yt_v2/audio.yml
  vae_ckpt_path: /mnt/data/shahbuland/owl-vaes/owl_audio_vae_v2.pt

wandb:
  name: shahbuland
  project: audio_models
  run_name: audio_rft_v1
